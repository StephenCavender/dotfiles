---
description: Generate comprehensive session summary with insights and metrics
agent: workflow-orchestrator
model: anthropic/claude-3-5-sonnet-20241022
---

Generate a complete session summary document analyzing the development session.

Create `session_{slug}_{timestamp}.md` with the following comprehensive analysis:

## Session Overview
- Session date and duration
- Primary goals and objectives
- Team members (agents) involved
- Project context and scope

## Key Actions Recap
- Major decisions made
- Features implemented or designed
- Problems solved
- Code reviews completed
- Architecture decisions recorded
- Tests written or test strategies defined
- Documentation created
- Bugs fixed or investigated

## Session Metrics
- **Total conversation turns**: [Count of user-assistant exchanges]
- **Total session cost**: [API costs incurred]
- **Agents consulted**: [List of agents and frequency of use]
- **Files created/modified**: [Count and types]
- **Commands executed**: [List of commands used]
- **Lines of code**: [Approximate count if applicable]

## AOT-Powered Efficiency Analysis
- **Velocity**: Tasks completed vs time spent with atomic convergence metrics
- **Agent utilization**: Most/least used agents and why, with AOT decomposition effectiveness
- **Bottlenecks identified**: Where did the session slow down? Analyzed through atomic sub-problem identification
- **Context switches**: How many times changed focus areas? Minimized through memoryless state transitions
- **Rework needed**: Any iterations required for quality? Analyzed through AOT quality-aware termination
- **Best practices followed**: Quality gates passed with AOT reasoning validation
- **Atomic Decomposition Success Rate**: Percentage of problems successfully solved through AOT framework
- **Markovian Reasoning Effectiveness**: How well memoryless transitions maintained answer-equivalence

## Quality Indicators
- Code review outcomes
- Security audit results (if performed)
- Performance considerations addressed
- Accessibility compliance checked
- Test coverage achieved
- Documentation completeness

## Collaboration Patterns
- Which agents collaborated most effectively?
- Were appropriate specialists consulted?
- Did collaboration protocols work smoothly?
- Any gaps in agent coordination?

## AOT-Enhanced Process Improvements
- **What worked well**:
  - Efficient AOT workflows and atomic decomposition usage
  - Effective agent collaboration through memoryless reasoning
  - Clear communication and requirements with AOT validation
  - Time-saving patterns through atomic convergence
  - Quality-aware termination effectiveness

- **What could be improved**:
  - Incomplete atomic decomposition of complex problems
  - Sub-optimal DAG dependency analysis
  - Quality-aware termination failures requiring rework
  - Better upfront AOT planning opportunities
  - Additional AOT automation possibilities

- **AOT Recommendations for next session**:
  - Enhanced atomic decomposition strategies
  - Improved DAG dependency identification
  - Better quality-aware termination criteria
  - AOT capability enhancements needed
  - Standards for memoryless reasoning transitions
  - Better atomic convergence validation processes

## Notable Highlights
- Clever solutions or approaches
- Complex problems solved elegantly
- Interesting technical decisions
- Learning moments or discoveries
- Unexpected challenges overcome
- Particularly effective agent contributions

## Action Items & Follow-ups
- [ ] Technical debt identified but not addressed
- [ ] Future enhancements or features planned
- [ ] Documentation to complete
- [ ] Tests to add or improve
- [ ] Performance optimizations to implement
- [ ] Security items to address
- [ ] Accessibility improvements needed

## Architecture Decision Records (ADRs)
- List any architectural decisions made
- Rationale and trade-offs discussed
- Alternative approaches considered
- Impact on system design

## AOT Knowledge Capture
- New atomic decomposition patterns discovered
- Reusable AOT solutions for future reference
- Memoryless reasoning patterns established
- Common AOT pitfalls to avoid
- Effective DAG structures identified
- Quality-aware termination successes and failures
- Atomic convergence best practices
- Markovian reasoning templates for reuse

## Session Artifacts
- Files created: [List with purpose]
- Commands defined: [Custom commands or workflows]
- Documentation generated: [Guides, READMEs, etc.]
- Tests implemented: [Coverage areas]
- Deployment artifacts: [CI/CD configs, etc.]

## Recommendations for Team
- Standards to adopt based on this session
- Training or knowledge sharing needed
- Tools or integrations to consider
- Process refinements to implement

## Cost-Benefit Analysis
- Session cost: $X.XX
- Value delivered: [Features, fixes, improvements]
- ROI assessment: [Was the investment worthwhile?]
- Cost optimization opportunities

## Next Steps
1. Immediate priorities from this session
2. Medium-term follow-ups
3. Long-term improvements identified
4. Handoff items for other team members

---

**Session Rating**: [1-10 based on productivity and outcomes]
**Would recommend this approach**: [Yes/No with explanation]
**Key takeaway**: [One-sentence summary of main accomplishment or learning]

---

*Generated by OpenCode Session Summary Tool*
*Timestamp: {timestamp}*
*Session Duration: {duration}*
*Total Cost: ${cost}*
